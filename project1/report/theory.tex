\section{Theory}
\subsection{Ordinary least squares}
We want to get a specific solution of the equation
\[ \hat{y} = \hat{X}\hat{\beta}+\hat{\epsilon} \]
Where $\hat{y}$ is a vector of our measured values, $\hat{X}$ is a matrix containing variables and determines how we want to fit our data, $\hat{\beta}$ is a vector of the parameters for our fit and $\hat{\epsilon}$ is a vector representing the error in our datapoints. The variables $\hat{y}$ and $\hat{X}$ are fixed and we want to choose parameters $\hat{\beta}$ in such a way that the errors $\hat{\epsilon}$ are minimized. An example might help clarify the situation\\
Lets say we have conducted an experiment where we have measured the position of a ball launched straight up into the air from a cannon. Neglecting air resistance we know that the analytical solution is on the form of a second order polynomial $x(t)=x_0+v_0t+at^2$, where $x_0 = x(t=0)$ is the position above ground of the ball before launch and $v_0=v(t=0)$ is the velocity of the ball immidiatly at launch. However, our measured results does not necessarily match this prefectly due to errors. In any case, if we measured the position $n$ times our linear algebra problem could be stated like this:
\begin{align*}
	\begin{bmatrix}
		\\ x(t_0) \\ x(t_1) \\ \vdots \\ x(t_{n-1}) \\ x(t_n)\\
	\end{bmatrix}
\end{align*}
\subsection{Ridge}
\subsection{Lasso}
\subsection{K-fold and and bootstrap}